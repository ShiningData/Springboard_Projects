def generate_metrics_df(model_name, X_train, X_test, y_train, y_test, 
                        y_train_pred, y_test_pred, y_train_pred_prob, 
                        y_test_pred_prob):
    """
    Generates a DataFrame containing various evaluation metrics for a given model.

    Parameters:
    ----------
    model_name : str
        The name of the model being evaluated.
    X_train : pd.DataFrame or np.ndarray
        Training set features.
    X_test : pd.DataFrame or np.ndarray
        Testing set features.
    y_train : pd.Series or np.ndarray
        True labels for the training set.
    y_test : pd.Series or np.ndarray
        True labels for the testing set.
    y_train_pred : pd.Series or np.ndarray
        Predicted labels for the training set.
    y_test_pred : pd.Series or np.ndarray
        Predicted labels for the testing set.
    y_train_pred_prob : pd.Series or np.ndarray
        Predicted probabilities for the training set.
    y_test_pred_prob : pd.Series or np.ndarray
        Predicted probabilities for the testing set.

    Returns:
    -------
    pd.DataFrame
        A DataFrame containing accuracy, precision, recall, F1 score, and ROC-AUC
        for both training and testing datasets.

    Metrics included:
    - Accuracy
    - Precision
    - Recall
    - F1 Score
    - ROC-AUC
    """


def create_confusion_matrix(y_data, y_pred, report_dir, file_path):
    """
    Generates and saves a confusion matrix plot based on the true and predicted labels.

    Parameters:
    ----------
    y_data : pd.Series or np.ndarray
        The actual true labels for the dataset.
    y_pred : pd.Series or np.ndarray
        The predicted labels from the model.
    report_dir : str
        The directory where the plot will be saved.
    file_path : str
        The filename (including extension) for saving the confusion matrix plot.

    Returns:
    -------
    None
        This function does not return anything. It saves the confusion matrix plot
        as an image in the specified directory.

    The confusion matrix is plotted using a heatmap with annotations, and it is saved
    as an image file. The plot includes labels for 'True' and 'Predicted' on the axes.

    Notes:
    ------
    - The saved plot will have tight bounding box settings to ensure no part of the plot is cropped.
    - The function also calls garbage collection after closing the plot.
    """


def create_roc_curve(y_pred_prob, y_data, X_data, report_dir, file_path):
    """
    Generates and saves a Receiver Operating Characteristic (ROC) curve plot along with the ROC-AUC score.

    Parameters:
    ----------
    y_pred_prob : pd.Series or np.ndarray
        The predicted probabilities for the positive class.
    y_data : pd.Series or np.ndarray
        The true labels for the dataset.
    X_data : pd.DataFrame or np.ndarray
        The features of the dataset (not used in the ROC calculation but likely passed for consistency).
    report_dir : str
        The directory where the ROC curve plot will be saved.
    file_path : str
        The filename (including extension) for saving the ROC curve plot.

    Returns:
    -------
    None
        This function does not return anything. It saves the ROC curve plot as an image in the specified directory.

    The ROC curve is plotted using the False Positive Rate (x-axis) against the True Positive Rate (y-axis).
    The function also calculates and displays the Area Under the ROC Curve (AUC) as part of the plot title.

    Notes:
    ------
    - The plot is saved with a tight bounding box to ensure no part of the plot is cropped.
    - The function calls garbage collection after the plot is closed.
    """


def create_precision_recall_curve(y_pred_prob, y_data, report_dir, file_path):
    """
    Generates and saves a Precision-Recall curve plot along with the Precision-Recall AUC score.

    Parameters:
    ----------
    y_pred_prob : pd.Series or np.ndarray
        The predicted probabilities for the positive class.
    y_data : pd.Series or np.ndarray
        The true labels for the dataset.
    report_dir : str
        The directory where the Precision-Recall curve plot will be saved.
    file_path : str
        The filename (including extension) for saving the Precision-Recall curve plot.

    Returns:
    -------
    None
        This function does not return anything. It saves the Precision-Recall curve plot as an image in the specified directory.

    The Precision-Recall curve is plotted with Recall on the x-axis and Precision on the y-axis. The function also calculates
    and displays the Area Under the Precision-Recall Curve (AUC) as part of the plot title.

    Notes:
    ------
    - The plot is saved with a tight bounding box to ensure no part of the plot is cropped.
    - The function calls garbage collection after the plot is closed.
    """


def create_dir(run_time, report_dir=None, model_dir=None, model_name=None):
    """
    Creates directories for storing model and report files based on the runtime and specified paths.

    Parameters:
    ----------
    run_time : str
        A timestamp or identifier for the current run, used to create unique directory names.
    report_dir : str, optional
        The base directory path where the report files should be stored. If None, no report directory is created.
    model_dir : str, optional
        The base directory path where the model files should be stored. If None, no model directory is created.
    model_name : str, optional
        The name of the model, used to create a subdirectory in the model store. If None, the model store directory is not created.

    Returns:
    -------
    str
        The path to the created directory (either model or report directory, depending on the input).
    
    Notes:
    ------
    - If `model_dir` is provided, a new subdirectory is created in `model_dir` with the format `{run_time}_{model_name}_model_store`.
    - If `report_dir` is provided, a new subdirectory is created in `report_dir` with the format `{run_time}_report_store`.
    - Logging information is generated to indicate whether the directories were successfully created or already existed.
    """


def model_preprocess(df):
    """
    Preprocesses the input dataframe by handling missing values and casting columns to appropriate data types.

    Parameters:
    ----------
    df : pd.DataFrame
        The input dataframe to be preprocessed.

    Returns:
    -------
    pd.DataFrame
        The preprocessed dataframe with missing values filled and columns cast to the appropriate types.

    Processing steps:
    - Missing values in the dataframe are replaced with the string "Missing".
    - The dataframe columns are then cast to appropriate data types using the `casting_columns` function.
    """


def group_stratified_split(df):
    """
    Splits the data into training and testing sets using group-based stratification.

    Parameters:
    ----------
    df : pd.DataFrame
        The input dataframe containing the features and target variable. The dataframe should include the columns
        'FE_DenialStatus' for the target and 'claimUniqueId' for grouping.

    Returns:
    -------
    X_train : pd.DataFrame
        Training set features.
    X_test : pd.DataFrame
        Testing set features.
    y_train : pd.Series
        Training set target labels.
    y_test : pd.Series
        Testing set target labels.

    Process:
    -------
    - Encodes the target variable 'FE_DenialStatus' using a LabelEncoder.
    - Uses GroupShuffleSplit to ensure that the train-test split maintains group stratification based on 'claimUniqueId'.
    - The stratification ensures that the mean target values for the train and test sets are approximately the same.
    - Removes columns 'claimUniqueId' and 'reorderServiceLineNbr' from the features before training.
    - Logs the shapes of the training and testing sets.

    Notes:
    ------
    - GroupShuffleSplit is used to ensure that the split respects the grouping in 'claimUniqueId'.
    - The function ensures that the mean target value across training and testing remains consistent with the overall dataset.
    """














=========================================================================================================

def get_denial_status(codes_dict, codes_list):
    """
    This function checks if any code in codes_list is marked as "Yes" in codes_dict.
    If a code has "Yes" as its value, the function returns "Denied". Otherwise, it returns "Accepted".
    
    Parameters:
    codes_dict (dict): A dictionary where keys are codes and values are "Yes" or other statuses.
    codes_list (list): A list of codes to be checked.
    
    Returns:
    str: "Denied" if any code is marked as "Yes" in the dictionary, otherwise "Accepted".
    """

def safe_eval_list(x):
    """
    Safely evaluates a string representation of a Python literal expression and returns a list.
    If the input cannot be evaluated (due to syntax or value errors), an empty list is returned.
    
    Parameters:
    x (str): A string representing a Python literal expression (e.g., "[1, 2, 3]").
    
    Returns:
    list: The evaluated list from the string. If the evaluation fails, returns an empty list.
    """

def convert_datetime(df, date_cols):
    """
    Converts specified columns in a dataframe to datetime format, handling errors by coercing invalid parsing to NaT.
    
    Parameters:
    df (pandas.DataFrame): The dataframe containing the columns to be converted.
    date_cols (list): A list of column names that should be converted to datetime.
    
    Returns:
    pandas.DataFrame: The dataframe with the specified columns converted to datetime format.
    """

def extract_element(x):
    """
    Extracts the first element from the input if it's a list. If the input is a string that looks like a list 
    (i.e., starts and ends with square brackets), it attempts to evaluate and extract the first element.
    If neither condition is met, it returns the input unchanged. If the evaluation of the string fails, it returns np.NaN.
    
    Parameters:
    x: The input which can be a list, a string representation of a list, or any other object.
    
    Returns:
    object: The first element if x is a list or a string that looks like a list, np.NaN if evaluation fails, or the input itself if it's neither.
    """

def col_value_extract(df, columns_to_update):
    """
    Applies the extract_element function to specified columns in a dataframe to extract the first element
    from each entry if it's a list or a string that represents a list.
    
    Parameters:
    df (pandas.DataFrame): The dataframe containing the columns to be updated.
    columns_to_update (list): A list of column names that need to be processed using the extract_element function.
    
    Returns:
    pandas.DataFrame: The dataframe with the specified columns updated, where each element is transformed 
    by the extract_element function.
    """

def create_actual_patient_features(
    df,
    p_age="patientAge",
    s_age="subscriberAge",
    p_gender="patientGender",
    s_gender="subscriberGender"
):
    """
    Creates actual patient age and gender features based on the given business logic.
    
    Business Logic:
    - If subscriberAge is populated and patientAge is null, the actual patient age will be subscriberAge.
    - If subscriberAge is null and patientAge is populated, the actual patient age will be patientAge.
    - If both subscriberAge and patientAge are populated, the actual patient age will be patientAge.
    - Ages above 89 are considered Protected Health Information (PHI), so any age over 89 is set to 199 to flag it as PHI.

    Parameters:
    df (pandas.DataFrame): The dataframe containing the patient and subscriber age and gender columns.
    p_age (str): The column name for the patient age.
    s_age (str): The column name for the subscriber age.
    p_gender (str): The column name for the patient gender.
    s_gender (str): The column name for the subscriber gender.
    
    Returns:
    pandas.DataFrame: The dataframe with two new columns:
    - "FE_actual_patientAge" which contains the calculated actual patient age.
    - "FE_actual_patientGender" which contains the actual patient gender based on the same logic as age.
    """

def preprocess_patient_relationship(value):
    """
    Cleans and processes the patient relationship values.
    
    This function performs the following steps:
    - If the value is null or NaN, it returns the value as is.
    - Converts the value to a string and splits it at the first period (".").
    - If the resulting cleaned value is a digit, it returns it as an integer (converted back to a string).
    - Otherwise, it returns the cleaned value.

    Parameters:
    value: The input value representing the patient relationship, which can be a number, string, or NaN.

    Returns:
    str: The processed and cleaned patient relationship value. If the value is a digit, it returns the numeric part; 
         otherwise, it returns the cleaned string.
    """

def rename_patient_relationship(df, col="patientRelationship"):
    """
    Maps patient relationship codes to their corresponding relationship descriptions in the dataframe.

    The function applies a mapping to replace numerical relationship codes in the specified column
    with human-readable descriptions. If a code does not have a mapping in the provided dictionary,
    it defaults to "Other Relationship".
    
    Parameters:
    df (pandas.DataFrame): The dataframe containing the patient relationship column to be renamed.
    col (str): The column name that contains the relationship codes (default is "patientRelationship").
    
    Returns:
    pandas.DataFrame: The dataframe with the patient relationship column updated to descriptive values.
    """

def preprocess_float_code(df, col):
    """
    Processes a column with float-like codes and converts them to string without unnecessary decimal places.

    This function:
    - Converts the column to a string.
    - If any values in the column end with ".0", it removes the ".0" from those values.

    Parameters:
    df (pandas.DataFrame): The dataframe containing the column to be processed.
    col (str): The name of the column to process.

    Returns:
    pandas.DataFrame: The dataframe with the specified column cleaned of trailing ".0" in float-like codes.
    """

def preprocess_cause_code(df, col):
    """
    Cleans the cause code column by removing any commas within the values.

    This function:
    - Checks if any values in the column contain commas.
    - If commas are found, they are replaced with empty strings (removing them).

    Parameters:
    df (pandas.DataFrame): The dataframe containing the cause code column to be processed.
    col (str): The name of the column to process.

    Returns:
    pandas.DataFrame: The dataframe with commas removed from the specified column.
    """

def remove_commas(x):
    """
    Removes commas from a string.

    This function:
    - If the input is a string, replaces all commas with an empty string.
    - If the input is not a string, it returns the input unchanged.

    Parameters:
    x (str): The string from which to remove commas.

    Returns:
    str: The string without commas, or the original input if not a string.
    """

def preprocess_line_quantity(df, col):
    """
    Preprocesses a column that contains line quantities by removing commas, handling decimal points, 
    and converting the values to integers.

    This function:
    - Removes commas from the values in the specified column using the `remove_commas` function.
    - Removes trailing ".0" and other decimal points that might be present in float-like values.
    - Converts the column to numeric, coercing errors (invalid parsing becomes NaN).
    - Fills any NaN values with 0.
    - Converts the column values to integers.

    Parameters:
    df (pandas.DataFrame): The dataframe containing the column to be processed.
    col (str): The name of the column to preprocess.

    Returns:
    pandas.DataFrame: The dataframe with the specified column processed, cleaned, and converted to integers.
    """

def preprocess_procedure_code_modifier(df, col):
    """
    Preprocesses the procedure code modifier column by converting the values to strings and 
    replacing commas with hyphens.

    This function:
    - Converts the values in the specified column to strings.
    - Replaces any commas (",") in the column values with hyphens ("-").

    Parameters:
    df (pandas.DataFrame): The dataframe containing the column to be processed.
    col (str): The name of the column to preprocess.

    Returns:
    pandas.DataFrame: The dataframe with the specified column processed, where commas are replaced by hyphens.
    """

def create_pointed_diagnosis_codes(codes, pointers=None):
    """
    Creates a list of pointed diagnosis codes based on a provided code string and optional pointers.

    This function works in two modes:
    1. If no pointers are provided, it splits the diagnosis codes by the "|" character and returns the list of codes.
    2. If pointers are provided:
        - It splits the codes by "." and uses the pointer indices to return the relevant diagnosis codes.
        - If a pointer is out of range or invalid, it returns the first code.
    
    Parameters:
    codes (str): A string of diagnosis codes, either separated by "|" or ".".
    pointers (str, optional): A string of pointer values separated by "." that indicates which codes to extract.

    Returns:
    list: A list of diagnosis codes pointed to by the provided pointer values, or the full list of codes if no pointers are given.
           If invalid inputs or pointers are encountered, returns NaN or the first code in the list.
    """

def create_pointed_diagnosis_type(type_codes, pointers=None):
    """
    Creates a list of pointed diagnosis types based on a provided type codes string and optional pointers.

    This function works in two modes:
    1. If no pointers are provided, it splits the diagnosis type codes by the "|" character and returns the list of type codes.
    2. If pointers are provided:
        - It splits the type codes by "." and uses the pointer indices to return the relevant diagnosis types.
        - If a pointer is out of range or invalid, it returns the first type code.
    
    Parameters:
    type_codes (str): A string of diagnosis type codes, either separated by "|" or ".".
    pointers (str, optional): A string of pointer values separated by "." that indicates which type codes to extract.

    Returns:
    list: A list of diagnosis types pointed to by the provided pointer values, or the full list of type codes if no pointers are given.
           If invalid inputs or pointers are encountered, returns NaN or the first type code in the list.
    """

def expand_list_columns(df, col_name):
    """
    Expands a dataframe column that contains lists into multiple columns, with each element of the list
    placed in a separate column.

    This function:
    - Determines the maximum length of the lists in the specified column.
    - For each list element, creates a new column (e.g., col_name_1, col_name_2, etc.).
    - Fills NaN values for rows where the list is shorter than the maximum length.

    Parameters:
    df (pandas.DataFrame): The dataframe containing the column with list values.
    col_name (str): The name of the column that contains the lists to expand.

    Returns:
    pandas.DataFrame: The original dataframe with the list column expanded into multiple columns.
    """

def safe_literal_eval(val):
    """
    Safely evaluates a string that represents a Python literal expression and returns the corresponding object.

    This function:
    - Attempts to evaluate the string using `ast.literal_eval`.
    - If the evaluation fails due to a ValueError or SyntaxError, it returns the original string.
    - If the value is an empty list ("[]"), it returns an empty list.

    Parameters:
    val (str): The string to evaluate, representing a Python literal.

    Returns:
    object: The evaluated Python object if successful, or the original string if evaluation fails.
    """

def pointed_diagnosis_codes_types(df, code, codetype):
    """
    Expands the diagnosis codes and types from list-like columns into individual columns in the dataframe.

    This function:
    - Fills missing values in the `code` and `codetype` columns with empty lists.
    - Applies `safe_literal_eval` to both columns to safely convert string representations of lists into actual lists.
    - Expands the `code` and `codetype` columns by creating new columns for each element of the lists, 
      naming the new columns sequentially (e.g., `code_1`, `code_2`).
    - Drops the original `code` and `codetype` columns after expansion.

    Parameters:
    df (pandas.DataFrame): The dataframe containing the diagnosis codes and types to be expanded.
    code (str): The name of the column containing the diagnosis codes (as lists or strings representing lists).
    codetype (str): The name of the column containing the diagnosis types (as lists or strings representing lists).

    Returns:
    pandas.DataFrame: The dataframe with the expanded diagnosis codes and types, with the original `code` and `codetype` columns removed.
    """

def serviceline_per_claim(df, claimid, sl_n):
    """
    Calculates the total number of service lines per claim and adds it as a new feature in the dataframe.

    This function:
    - Converts the `sl_n` column (service line number) to string format.
    - Groups the dataframe by `claimid` to count the number of service lines (`sl_n`) for each claim.
    - Creates a dictionary mapping each `claimid` to its corresponding count of service lines.
    - Adds a new column, `FE_total_sln_per_claim`, which contains the total number of service lines per claim.
    - Ensures that the values in the new column are stored as integers.

    Parameters:
    df (pandas.DataFrame): The dataframe containing claim and service line information.
    claimid (str): The name of the column representing the unique claim identifier.
    sl_n (str): The name of the column representing the service line number.

    Returns:
    pandas.DataFrame: The original dataframe with an additional column `FE_total_sln_per_claim` 
                      representing the total number of service lines per claim.
    """


def create_date_features(df, date_cols):
    """
    Creates new features related to date differences and service line statuses based on date columns.

    This function:
    - Converts the specified date columns to datetime format.
    - Calculates the number of days between the claim submission date and the service date, and stores it in a new column `FE_claimstate_to_service_days`.
    - Calculates the number of days between the service end date and the service start date, storing it in `FE_service_over_day`.
    - Fills missing values in `FE_service_over_day` with 999.0.
    - Converts `FE_service_over_day` to integer type.
    - Adds a new column `FE_serviceLineDateStatus` to indicate whether a service line is "Open" or "Closed" based on the presence of a service end date.

    Parameters:
    df (pandas.DataFrame): The dataframe containing the date columns to be processed.
    date_cols (list): A list of column names representing date fields used to compute the features. Expected indices:
                      - date_cols[0]: Claim submission date
                      - date_cols[3]: Service start date
                      - date_cols[4]: Service end date

    Returns:
    pandas.DataFrame: The original dataframe with new date-related features added.
    """


def casting_columns(df):
    """
    Casts specific columns in the dataframe to their appropriate data types, either string (categorical) or numeric.

    This function:
    - Defines lists of columns that should be cast to string (categorical columns) and numeric (integer or float).
    - Loops through the categorical columns, casting each one to a string type.
    - Loops through the numerical columns, casting each one to an integer type unless it's in a predefined list, 
      in which case it is cast to a float type.

    Parameters:
    df (pandas.DataFrame): The dataframe containing the columns to be cast.

    Returns:
    pandas.DataFrame: The dataframe with the specified columns cast to their appropriate types.
    """




