from hyperopt import fmin, tpe, Trials, STATUS_OK
import catboost as cb
from sklearn.metrics import roc_auc_score

# Define the objective function
def objective(params):
    # Cast hyperparameters to their correct types
    params['iterations'] = int(params['iterations'])
    params['depth'] = int(params['depth'])
    params['border_count'] = int(params['border_count'])
    params['scale_pos_weight'] = int(params['scale_pos_weight'])
    
    # Initialize the CatBoostClassifier with the hyperparameters
    model = cb.CatBoostClassifier(
        **params,
        verbose=0,
        cat_features=categorical_features_indices  # Adjust for your dataset
    )
    
    # Fit the model (use your training data)
    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=100, verbose=0)
    
    # Predict probabilities and compute AUC score (use your validation data)
    preds_proba = model.predict_proba(X_val)[:, 1]  # For binary classification
    auc = roc_auc_score(y_val, preds_proba)
    
    return {'loss': -auc, 'status': STATUS_OK}

# Initialize trials to keep track of the optimization process
trials = Trials()

# Run the optimization
best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, trials=trials)
print("Best hyperparameters found:", best)
