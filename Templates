import pandas as pd
import numpy as np
import shap
import multiprocessing
from autogluon.tabular import TabularPredictor
from sklearn.preprocessing import LabelEncoder

# Assume X_train and model are already defined
# Replace 'label' with your target column
X_train = X_train.drop(columns=['label'])

# Step 1: Encode categorical variables
def encode_data(data):
    label_encoders = {}
    for col in data.select_dtypes(include=['object']).columns:
        le = LabelEncoder()
        data[col] = le.fit_transform(data[col])
        label_encoders[col] = le
    return data, label_encoders

X_train, label_encoders = encode_data(X_train)

# Step 2: Divide the dataframe into 20 portions
def divide_into_chunks(data, num_chunks=20):
    chunk_size = len(data) // num_chunks
    return [data.iloc[i * chunk_size:(i + 1) * chunk_size] for i in range(num_chunks)]

chunks = divide_into_chunks(X_train, num_chunks=20)

# Step 3: Define function to calculate SHAP values for each chunk
def calculate_shap_values(chunk):
    explainer = shap.KernelExplainer(model.predict_proba, chunk.sample(100))  # Use sampling for background data
    shap_values = explainer.shap_values(chunk)
    return shap_values

# Step 4: Run SHAP calculations in parallel
if __name__ == "__main__":
    with multiprocessing.Pool(processes=20) as pool:
        results = pool.map(calculate_shap_values, chunks)

# Step 5: Combine results from all chunks
combined_shap_values = [shap_val for chunk_shap in results for shap_val in chunk_shap]

# Step 6: Visualize SHAP values for the first instance
shap.initjs()
shap.force_plot(explainer.expected_value[1], combined_shap_values[0][1], X_train.iloc[0])
