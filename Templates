FEATURE IMPORTANCE:

 4.7 Model Outcome Analysis: Global Feature Importance

 4.7.1 FMOL Ensemble Model Global Feature Importance

The RulexAI global feature importance analysis for FMOL provides valuable insights into the drivers of claim denial predictions across two temporal windows: 12-month and 18-month datasets. This analysis quantifies the contribution of each feature to model predictions, with positive values indicating factors that increase denial probability and negative values representing factors that decrease denial likelihood.

 4.7.1.1 12 Months FMOL Data

For the 12-month FMOL dataset, the analysis reveals distinct patterns in feature importance for both claim approval (class 0) and denial (class 1) outcomes:

Class 0 (Claim Approval) Drivers:
- Provider NPI emerges as the most significant factor (0.0223) influencing claim approval, suggesting that certain providers have established effective claims submission practices.
- Claim facility code (0.0051) and service line revenue code (-0.0015) also demonstrate notable influence on approval outcomes.
- The strongest negative predictors for approval include claim frequency code (-0.2651), FE_actual_patientAge (-0.2188), and service line quantity (-0.1349), indicating these factors increase denial likelihood when present in certain configurations.

Class 1 (Claim Denial) Drivers:
- Service line revenue code shows the highest positive impact (0.0831) on denial predictions, indicating certain revenue codes are strongly associated with denial outcomes.
- Service line quantity (0.0279) and FE_serviceLinePointedDiagnosisTypeCodes_1 (0.0045) also contribute significantly to denial predictions.
- Patient demographic factors show minimal impact, with FE_actual_patientGender having very low importance (8.94E-05).
- Strong negative contributors to denial prediction include FE_actual_patientAge (-0.0897) and provider NPI (-0.0489), suggesting these factors, when present in certain configurations, reduce denial likelihood.

 4.7.1.2 18 Months FMOL Data

Extending the analysis to the 18-month FMOL dataset reveals both consistency and evolution in feature importance:

Class 0 (Claim Approval) Drivers:
- Provider NPI maintains significant importance (0.0051), though its relative influence has decreased compared to the 12-month dataset.
- Service line unit of measure (-0.0052) and service line revenue code (-0.0071) show consistent negative impact on approval probability.
- Claim frequency code (-0.2716) remains the strongest negative predictor for approval, consistent with the 12-month analysis.

Class 1 (Claim Denial) Drivers:
- Service line procedure code (-0.0027) and service line revenue code (-0.0029) show modest negative impact on denial prediction.
- Claim facility code (-0.0050) and provider NPI (-0.0080) emerge as stronger negative contributors to denial in the extended dataset.
- Service line quantity (-0.1332) shows significant negative association with denials in the 18-month data.

The 18-month analysis demonstrates a shift in feature importance patterns compared to the 12-month window, suggesting temporal evolution in denial patterns. The reduced magnitude of importance values in the 18-month data may indicate more complex interrelationships between features over the extended timeframe.

 4.7.2 GRADY Ensemble Model Global Feature Importance

The Grady Health System data exhibits distinct feature importance patterns compared to FMOL, highlighting the importance of client-specific model customization in healthcare claim denial prediction.

 4.7.2.1 12 Months Grady Data

The 12-month Grady dataset shows the following feature importance patterns:

Class 0 (Claim Approval) Drivers:
- Service line procedure code emerges as the most significant positive factor (0.0017) for claim approval.
- Service line procedure code qualifier (-0.0038), service line quantity (-0.0096), and service line unit of measure (-0.0163) all show negative association with approval.
- Patient age (FE_actual_patientAge) shows the strongest negative impact (-0.2902) on approval probability, indicating older patient demographics may face higher denial rates.

Class 1 (Claim Denial) Drivers:
- Claim facility code shows the strongest positive association (0.0028) with denial outcomes.
- Patient demographics, including FE_actual_patientGender (-0.0015) and FE_actual_patientAge (-0.0800), show negative influence on denial probability.
- Service line quantity (-0.1750) demonstrates significant negative association with denials, indicating that higher quantity services may face lower denial rates in the Grady environment.

 4.7.2.2 18 Months Grady Data

The extended 18-month Grady dataset reveals evolution in feature importance:

Class 0 (Claim Approval) Drivers:
- Service line procedure code maintains positive importance (0.0016), consistent with the 12-month analysis.
- Service line quantity (-0.0465) and claim frequency code (-0.1372) show strong negative associations with approval.
- Patient age (FE_actual_patientAge) remains the most significant negative predictor (-0.2613) for approval.

Class 1 (Claim Denial) Drivers:
- Claim frequency code emerges as the strongest positive predictor (0.0170) for denials in the extended dataset.
- Claim facility code (0.0000) shows negligible impact on denial probability, a notable change from the 12-month analysis.
- Service line quantity (-0.1370) maintains its strong negative association with denial outcomes.

 Cross-Client Comparative Analysis

The comparative analysis between FMOL and Grady feature importance reveals several insights:

1. Client-Specific Patterns: The two healthcare organizations show distinct feature importance patterns, highlighting the value of customized modeling approaches:
   - FMOL shows stronger influence from provider NPI and revenue codes
   - Grady exhibits greater sensitivity to procedure codes and patient demographics

2. Temporal Consistency: Both clients show relatively consistent patterns between 12-month and 18-month analyses for class 0 (approval) predictors, suggesting stable patterns in factors that lead to successful claims.

3. Denial Factor Evolution: The class 1 (denial) predictors show more variation between the 12-month and 18-month analyses, indicating that denial patterns may evolve more rapidly and require more frequent model updates.

4. Demographic Factors: Patient age shows significant importance in the Grady dataset but more moderate influence in the FMOL data, suggesting organizational differences in patient population or service mix.

5. Common Drivers: Service line quantity emerges as an important factor across both client environments, consistently showing negative association with approval probability.

These global feature importance patterns inform targeted interventions in the revenue cycle process, enabling each healthcare organization to focus improvement efforts on the most influential factors in their specific environment. The analysis will be updated quarterly to track evolving patterns and ensure the model maintains alignment with changing payer behaviors and coding requirements.

===================================

# 4.8 Precision-Recall Curve Analysis

## Overview of Precision-Recall Evaluation for Healthcare Claim Denial Prediction

The Precision-Recall curve represents a critical performance evaluation tool for our healthcare claim denial predictor model, particularly given the inherent class imbalance in claims data where denials typically constitute a minority class. Unlike ROC curves that plot true positive rate against false positive rate, Precision-Recall curves specifically focus on the trade-off between precision (positive predictive value) and recall (sensitivity) across various classification thresholds.

In the context of our healthcare claim denial predictor, this evaluation metric holds particular significance:

- **Precision** measures the proportion of claims predicted as denials that are actually denied. High precision minimizes false positives, which is operationally important as each flagged claim requires resource-intensive review.

- **Recall** quantifies the proportion of actual denials that are correctly identified by the model. High recall ensures that potentially problematic claims are not missed, which directly impacts revenue preservation.

The area under the Precision-Recall curve (PR AUC) provides a single-value performance metric that captures the model's ability to maintain both high precision and high recall across different threshold settings. This metric is particularly valuable for imbalanced classification problems like claim denial prediction, where standard accuracy can be misleading due to the prevalence of the majority class.

## Comparative Analysis of Model Variants

### FMOL Client Performance

#### 12-Month Dataset Analysis
The Precision-Recall curves for the FMOL 12-month dataset demonstrate the relative performance of our three model variants (AUTOGLUON, Catboost, and the Ensemble model). The ensemble approach consistently maintains higher precision across recall levels compared to either individual model, validating our architectural decision to combine these complementary algorithms.

At high recall thresholds (>0.8), where operational focus often lies to capture most potential denials, the ensemble model maintains precision approximately 15% higher than the Catboost model alone and 8% higher than AUTOGLUON. This translates directly to operational efficiency by reducing false positives that would require unnecessary review.

#### 18-Month Dataset Analysis
The extended 18-month FMOL dataset shows interesting evolution in model performance. The PR curves reveal that all three models benefit from the additional historical data, with increased PR AUC scores across the board. However, the ensemble model's advantage becomes even more pronounced, particularly in the critical high-recall region (0.7-0.9) where operational thresholds are typically set.

The enhanced performance on the 18-month dataset validates our continuous learning approach and suggests that temporal patterns in denial behavior provide valuable signal for prediction.

### Grady Client Performance

#### 12-Month Dataset Analysis
For the Grady 12-month dataset, the Precision-Recall curves reveal distinct performance characteristics compared to FMOL. While the ensemble model maintains superior performance, the gap between AUTOGLUON and Catboost is more pronounced, with AUTOGLUON demonstrating particularly strong performance in the mid-recall range (0.4-0.7).

This client-specific variation in algorithm performance further justifies our ensemble approach, which effectively leverages the strengths of each algorithm while mitigating their individual weaknesses.

#### 18-Month Dataset Analysis
The Grady 18-month PR curves show significant performance improvements compared to the 12-month dataset across all model variants. Most notably, the ensemble model achieves exceptional precision (>0.85) even at high recall levels (0.8), representing a substantial improvement in predictive performance.

This marked improvement suggests that Grady's denial patterns may exhibit stronger temporal dependencies that become more detectable with extended historical data, highlighting the value of our customized approach to each client environment.

## Threshold Selection Implications

The Precision-Recall curves provide essential guidance for operational threshold selection in production deployment. By visualizing the precision-recall trade-off, revenue cycle management teams can select optimal operating points based on their specific business priorities:

1. **Resource-Constrained Environments**: Organizations with limited review capacity can select thresholds that prioritize precision, ensuring that flagged claims have high probability of actual denial.

2. **Revenue Protection Focus**: Organizations prioritizing maximum denial capture can select thresholds that favor recall, accepting additional false positives to minimize missed denials.

3. **Balanced Approach**: Most organizations benefit from thresholds in the "elbow" region of the PR curve, where marginal precision sacrifices yield substantial recall improvements.

The ensemble model's superior PR curve performance across all client datasets and temporal windows supports standardizing on the 0.5 probability threshold, eliminating the need for artificially lowered thresholds that were required with previous model implementations.

## Conclusion

The Precision-Recall curve analysis demonstrates the robust performance of our ensemble approach across different client environments and temporal windows. The consistently superior PR AUC scores of the ensemble model validate our architectural decisions and feature engineering approach.

Furthermore, the analysis reveals that extended historical data (18-month vs. 12-month) yields significant performance improvements, particularly for the Grady dataset. This finding supports our implementation of monthly retraining using 18-month rolling windows to maintain optimal model performance.

The Precision-Recall evaluation framework will continue to serve as a primary performance monitoring tool, enabling ongoing assessment of model effectiveness and informing threshold adjustments as operational requirements evolve.

=========================================================================================================

