import pandas as pd
from pycaret.classification import load_model, predict_model
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import OneHotEncoder

# Load the saved PyCaret model
model = load_model('your_model_name')

# Load the dataset for prediction
data = pd.read_csv('your_data_file.csv')

# Use OneHotEncoder to ensure we handle categorical variables like in training
encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
encoded_data = pd.DataFrame(encoder.fit_transform(data.select_dtypes(include=['object'])))
encoded_data.columns = encoder.get_feature_names_out(data.select_dtypes(include=['object']).columns)

# Add any non-categorical columns back to the dataframe
non_categorical_data = data.select_dtypes(exclude=['object']).reset_index(drop=True)
encoded_data = pd.concat([non_categorical_data, encoded_data], axis=1)

# Ensure the encoded data has the same columns as the model expects
# Reindex to ensure all columns expected by the model are present
expected_features = predict_model(model, data=data).drop(columns=['Prediction', 'Score']).columns
encoded_data = encoded_data.reindex(columns=expected_features, fill_value=0)

# Extract the decision tree classifier from the PyCaret model pipeline
decision_tree_model = [step for step in model.named_steps.values() if isinstance(step, DecisionTreeClassifier)][0]

# Function to determine the node level for each prediction
def get_node_level(row):
    row = row.values.reshape(1, -1)  # Reshape the row to match the expected input format
    node_indicator = decision_tree_model.decision_path(row)
    node_index = node_indicator.indices
    return len(node_index)  # The depth level where the prediction was made

# Apply the node level function to the encoded data
encoded_data['Node_Level'] = encoded_data.apply(get_node_level, axis=1)

# Add a 'Max_Depth_Level' column with the maximum depth level of the tree
encoded_data['Max_Depth_Level'] = decision_tree_model.tree_.max_depth

# Use PyCaret's predict_model to make predictions (this applies the necessary preprocessing)
predictions = predict_model(model, data=data)

# Combine the node levels with the original predictions
final_predictions = pd.concat([predictions, encoded_data[['Node_Level', 'Max_Depth_Level']]], axis=1)

# Save the final predictions with node levels and max depth levels
final_predictions.to_csv('predictions_with_node_and_max_depth_levels.csv', index=False)

print("Predictions with node levels and max depth levels saved to 'predictions_with_node_and_max_depth_levels.csv'")
