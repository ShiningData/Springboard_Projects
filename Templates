import pickle
import pandas as pd
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
from sklearn.preprocessing import label_binarize
from sklearn.utils.multiclass import unique_labels

# Load the saved CatBoost model
with open('catboost_model.pkl', 'rb') as model_file:
    model = pickle.load(model_file)

# Load your table with actual and predicted values
# Replace 'your_data.csv' with the path to your data file
df = pd.read_csv('your_data.csv')

# Assume 'actual' and 'predicted' are the column names in your table
y_true = df['actual']
y_pred = df['predicted']

# Calculate accuracy
accuracy = accuracy_score(y_true, y_pred)
print(f'Accuracy: {accuracy:.4f}')

# Calculate precision, recall, F1 score
precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

# Calculate AUC
# Get unique classes
classes = unique_labels(y_true, y_pred)
n_classes = len(classes)

# Binarize the output
y_true_bin = label_binarize(y_true, classes=classes)
y_pred_bin = label_binarize(y_pred, classes=classes)

# Compute AUC for each class
try:
    auc = roc_auc_score(y_true_bin, y_pred_bin, average='weighted', multi_class='ovr')
    print(f'AUC: {auc:.4f}')
except ValueError as e:
    print(f'Error calculating AUC: {e}')
