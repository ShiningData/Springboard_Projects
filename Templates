import pandas as pd
import numpy as np
from scipy.spatial.distance import cosine
from fastdtw import fastdtw
from scipy.spatial.distance import euclidean
import itertools

# Load the dataset
df = pd.read_csv('your_dataset.csv')

# Pivot the dataset
pivot_df = df.pivot_table(index='RLTN_PWR_ID', columns='TRAN_CD', values='VOLUME', aggfunc='sum').fillna(0)

# Get the list of TRAN_CDs
tran_cds = pivot_df.columns

# Function to calculate DTW distance and cosine similarity
def calculate_dtw_cosine(series1, series2):
    dtw_distance, _ = fastdtw(series1, series2, dist=euclidean)
    cosine_sim = 1 - cosine(series1, series2)
    return dtw_distance, cosine_sim

# Create a DataFrame to store the results
results = []

# Iterate over all pairs of TRAN_CDs
for (cd1, cd2) in itertools.combinations(tran_cds, 2):
    series1 = pivot_df[cd1].values
    series2 = pivot_df[cd2].values
    dtw_distance, cosine_sim = calculate_dtw_cosine(series1, series2)
    results.append({'TRAN_CD_1': cd1, 'TRAN_CD_2': cd2, 'DTW_Distance': dtw_distance, 'Cosine_Similarity': cosine_sim})

# Convert the results into a DataFrame
results_df = pd.DataFrame(results)

# Filter for high similarity pairs (you can adjust the thresholds as needed)
dtw_threshold = 100  # Example threshold for DTW distance
cosine_threshold = 0.8  # Example threshold for cosine similarity

consolidation_recommendations = results_df[(results_df['DTW_Distance'] < dtw_threshold) & 
                                           (results_df['Cosine_Similarity'] > cosine_threshold)]

# Group the consolidations
consolidations = consolidation_recommendations.groupby('TRAN_CD_1').agg({
    'TRAN_CD_2': lambda x: list(x),
    'DTW_Distance': 'mean',
    'Cosine_Similarity': 'mean'
}).reset_index()

# Output the results
print(consolidations)
