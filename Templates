from pyspark.sql import SparkSession
from pyspark.sql.functions import concat, lit

# Create SparkSession
spark = SparkSession.builder \
    .appName("Rules Frequency Analysis") \
    .getOrCreate()

# Assume you have already loaded your table into a DataFrame named "RULES_FREQUENCY_TABLE"

# Register the DataFrame as a temporary view
RULES_FREQUENCY_TABLE.createOrReplaceTempView("rules_frequency")

# Define the SQL query
sql_query = """
SELECT 
    UID_PRULES,
    CONCAT(
        CASE EXECUTION_MONTH
            WHEN 1 THEN 'Jan'
            WHEN 2 THEN 'Feb'
            WHEN 3 THEN 'Mar'
            WHEN 4 THEN 'Apr'
            WHEN 5 THEN 'May'
            WHEN 6 THEN 'Jun'
            WHEN 7 THEN 'Jul'
            WHEN 8 THEN 'Aug'
            WHEN 9 THEN 'Sep'
            WHEN 10 THEN 'Oct'
            WHEN 11 THEN 'Nov'
            WHEN 12 THEN 'Dec'
        END,
        '_',
        EXECUTION_YEAR
    ) AS MONTH_YEAR,
    NUM_EXECUTIONS
FROM 
    rules_frequency
WHERE
    (EXECUTION_YEAR = YEAR(CURRENT_DATE()) AND EXECUTION_MONTH >= MONTH(CURRENT_DATE()))
    OR
    (EXECUTION_YEAR = YEAR(CURRENT_DATE()) + 1 AND EXECUTION_MONTH <= MONTH(CURRENT_DATE()))
"""

# Execute the SQL query
result_df = spark.sql(sql_query)

# Show the result DataFrame
result_df.show()
