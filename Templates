When you blend models in PyCaret, you're essentially combining multiple individual models to make a collective decision or prediction. The blending method works by taking a weighted average of predictions (for regression) or votes (for classification) from individual models. Due to the nature of this technique, the direct feature importance from the blended model is not inherently available. 

Here's why:

1. **Different Models Have Different Importance Metrics**: If your top 3 models are of different types (e.g., a decision tree, a logistic regression, and a random forest), each model has its own way of calculating feature importance. For instance, tree-based models might use Gini importance, while linear models might use coefficients. Combining these into a single unified measure is not straightforward.

2. **Blended Models Are Not Trained Directly**: The individual models in the blend are trained separately on the data, and the blending procedure itself doesn't involve a direct training process where feature importance can be computed.

3. **Weighted Contributions**: Even if all the models in the blend were of the same type (e.g., all decision trees), each model might assign a different importance to the features. When these models are blended, the resulting importance would be a function of both the importance assigned by each model and the weight or importance of each model in the blend.

If you really need a measure of feature importance from the blended model, you might consider the following approach:

1. **Aggregate Feature Importance from Individual Models**: One crude method is to get the feature importance of each individual model and then take an average. This assumes each model's importance measure is comparable and of equal weight, which may not be the case if they're of different types.

2. **Use a Model-Agnostic Approach**: Methods like Permutation Importance or SHAP (SHapley Additive exPlanations) can be used to calculate feature importance in a model-agnostic way. You can apply these techniques to the blended model's predictions to get an idea of overall feature importance. Keep in mind that these methods can be computationally intensive.

3. **Consider a Different Ensemble Method**: Instead of blending, you might use stacking, where you stack the predictions of base models and train a meta-model on top. The feature importance of this meta-model can give insights into how it weighs the predictions of the base models, but it won't give direct importance of the original features.

Remember, while feature importance is a valuable tool for interpretation, it should be used with care and understanding of the underlying assumptions and limitations.
