def group_stratified_split(df):
    """
    Performs a stratified train-validation-test split on the dataset, ensuring the target
    variable distribution is maintained across splits and groups by a specific column.

    Parameters:
    df (pd.DataFrame): The input dataframe to be split.

    Returns:
    Tuple: A tuple containing:
        X_train (pd.DataFrame): The training set features.
        X_valid (pd.DataFrame): The validation set features.
        X_test (pd.DataFrame): The test set features.
        y_train (pd.Series): The training set target variable.
        y_valid (pd.Series): The validation set target variable.
        y_test (pd.Series): The test set target variable.
    """
    
    # Encode Target Variable
    label_encoder = LabelEncoder()
    df["FE_DenialStatus"] = label_encoder.fit_transform(df["FE_DenialStatus"])

    # Split data
    X = df.drop(columns=["FE_DenialStatus"])
    y = df["FE_DenialStatus"]
    groups = df["ClaimUniqueID"]

    # Initialize GroupShuffleSplit for the first train-test split
    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)

    for train_idx, test_idx in gss.split(X, y, groups):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        # Check stratification
        if (y_train.mean() != y.mean()) or (y_test.mean() != y.mean()):
            continue
        break
    
    # Now, perform a stratified split on the training data to create a validation set
    gss_val = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=42)  # 25% of train = 20% of total

    for train_idx, valid_idx in gss_val.split(X_train, y_train, groups.iloc[train_idx]):
        X_train, X_valid = X_train.iloc[train_idx], X_train.iloc[valid_idx]
        y_train, y_valid = y_train.iloc[train_idx], y_train.iloc[valid_idx]
        
        # Check stratification
        if (y_train.mean() != y.mean()) or (y_valid.mean() != y.mean()):
            continue
        break

    # Keep certain columns in the unseen data for reference
    reference_cols = ['reorderServiceLineID']
    X_train = X_train.drop(columns=reference_cols)
    X_valid = X_valid.drop(columns=reference_cols)
    X_test = X_test.drop(columns=reference_cols)

    logging.info('Training Data Shape For Modeling: ' + str(X_train.shape))
    logging.info('Validation Data Shape For Validation: ' + str(X_valid.shape))
    logging.info('Test Data Shape For Predictions: ' + str(X_test.shape))

    # Clean up memory
    del X, y
    gc.collect()

    return X_train, X_valid, X_test, y_train, y_valid, y_test
