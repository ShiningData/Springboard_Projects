# model_explainability.py

import pandas as pd
import numpy as np
import shap
import joblib
from catboost import CatBoostClassifier
from autogluon.tabular import TabularPredictor

class EnsembleModelInterpreter:
    def __init__(self, 
                 catboost_model_path: str, 
                 autogluon_model_path: str,
                 data: pd.DataFrame):
        """
        Initializes the EnsembleModelInterpreter with trained CatBoost and AutoGluon models.

        Parameters:
        - catboost_model_path (str): Path to the serialized CatBoost model.
        - autogluon_model_path (str): Path to the serialized AutoGluon predictor.
        - data (pd.DataFrame): The dataset used to fit the SHAP explainers.
        """
        # Load CatBoost model
        try:
            self.catboost_model = CatBoostClassifier()
            self.catboost_model.load_model(catboost_model_path)
            print("CatBoost model loaded successfully.")
        except Exception as e:
            print(f"Error loading CatBoost model: {e}")
            raise e

        # Load AutoGluon model
        try:
            self.autogluon_predictor = TabularPredictor.load(autogluon_model_path)
            print("AutoGluon predictor loaded successfully.")
        except Exception as e:
            print(f"Error loading AutoGluon predictor: {e}")
            raise e

        # Store data for SHAP explainers
        self.data = data

        # Initialize SHAP explainers
        try:
            self.catboost_explainer = shap.TreeExplainer(self.catboost_model, data)
            print("SHAP TreeExplainer for CatBoost initialized.")
        except Exception as e:
            print(f"Error initializing SHAP for CatBoost: {e}")
            raise e

        try:
            # Assuming AutoGluon uses a tree-based model; adjust if different
            self.autogluon_explainer = shap.Explainer(self.autogluon_predictor.predict_proba, data)
            print("SHAP Explainer for AutoGluon initialized.")
        except Exception as e:
            print(f"Error initializing SHAP for AutoGluon: {e}")
            raise e

    def predict(self, instance: pd.DataFrame) -> pd.DataFrame:
        """
        Generates ensemble prediction by averaging probabilities from both models.

        Parameters:
        - instance (pd.DataFrame): A single instance for prediction.

        Returns:
        - pd.DataFrame: Ensemble class probabilities and predicted class label.
        """
        try:
            # CatBoost prediction probabilities
            catboost_probs = self.catboost_model.predict_proba(instance)
            catboost_df = pd.DataFrame(catboost_probs, columns=self.catboost_model.classes_)
            print("CatBoost prediction probabilities obtained.")

            # AutoGluon prediction probabilities
            autogluon_probs = self.autogluon_predictor.predict_proba(instance)
            autogluon_df = autogluon_probs.reset_index(drop=True)
            print("AutoGluon prediction probabilities obtained.")

            # Ensure both dataframes have the same classes
            if not all(catboost_df.columns == autogluon_df.columns):
                raise ValueError("Class labels of CatBoost and AutoGluon models do not match.")

            # Average probabilities
            ensemble_probs = (catboost_df + autogluon_df) / 2
            ensemble_probs['ensemble_pred'] = ensemble_probs.idxmax(axis=1)
            print("Ensemble prediction probabilities computed.")

            return ensemble_probs
        except Exception as e:
            print(f"Error during prediction: {e}")
            raise e

    def explain_prediction(self, instance: pd.DataFrame) -> dict:
        """
        Computes and combines SHAP values from both models for the given instance.

        Parameters:
        - instance (pd.DataFrame): A single instance for explanation.

        Returns:
        - dict: Combined SHAP values per feature.
        """
        try:
            # SHAP values for CatBoost
            shap_catboost = self.catboost_explainer(instance)
            shap_catboost_values = shap_catboost.values
            print("SHAP values for CatBoost computed.")

            # SHAP values for AutoGluon
            shap_autogluon = self.autogluon_explainer(instance)
            shap_autogluon_values = shap_autogluon.values
            print("SHAP values for AutoGluon computed.")

            # Average SHAP values
            combined_shap = (shap_catboost_values + shap_autogluon_values) / 2
            print("SHAP values combined.")

            # Create a dictionary of feature names and their SHAP values
            feature_shap = dict(zip(instance.columns, combined_shap[0]))
            return feature_shap
        except Exception as e:
            print(f"Error during SHAP computation: {e}")
            raise e

    def prepare_explainability_data(self, instance: pd.DataFrame) -> dict:
        """
        Prepares data for API consumption for model interpretability.

        Parameters:
        - instance (pd.DataFrame): A single instance for explanation.

        Returns:
        - dict: A dictionary with prediction probabilities and SHAP values for the instance.
        """
        try:
            # Get ensemble prediction
            ensemble_prediction = self.predict(instance)
            print("Ensemble prediction obtained.")

            # Get SHAP values for the instance
            shap_values = self.explain_prediction(instance)
            print("SHAP values for interpretability obtained.")

            # Prepare the data to send via API
            response_data = {
                "ensemble_prediction": ensemble_prediction.to_dict(orient='records'),
                "shap_values": shap_values
            }

            return response_data
        except Exception as e:
            print(f"Error preparing explainability data: {e}")
            raise e

# Example usage
if __name__ == "__main__":
    # Paths to the trained models
    catboost_model_path = 'path/to/catboost_model.cbm'
    autogluon_model_path = 'path/to/autogluon_predictor'

    # Load or prepare the data used for model training
    # This should be the same data used to fit the models for accurate SHAP explanations
    data = pd.read_csv('path/to/training_data.csv')

    # Initialize the interpreter
    interpreter = EnsembleModelInterpreter(
        catboost_model_path=catboost_model_path,
        autogluon_model_path=autogluon_model_path,
        data=data
    )

    # Example instance for prediction and explanation
    # Replace with your actual instance
    instance = data.sample(1).drop('target_column', axis=1)  # Replace 'target_column' accordingly

    # Prepare data for API request
    explainability_data = interpreter.prepare_explainability_data(instance)
    print("Data for API consumption:")
    print(explainability_data)
