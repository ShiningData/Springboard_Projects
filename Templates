import pandas as pd
from itertools import combinations
from collections import defaultdict
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Example data
data = {
    'RLTN_PWR_ID': [1, 1, 2, 2, 3, 3, 3, 3],
    'TRAN_CD': ['A', 'B', 'A', 'D', 'C', 'D', 'E', 'F'],
    'VOLUME': [100, 150, 200, 250, 300, 350, 400, 450]
}

df = pd.DataFrame(data)

# Create a co-occurrence matrix for transaction codes
trans_codes = sorted(set(df['TRAN_CD']))
index = {code: idx for idx, code in enumerate(trans_codes)}
matrix = np.zeros((len(trans_codes), len(trans_codes)))

# Populate the matrix based on co-occurrence within the same RLTN_PWR_ID
for _, group in df.groupby('RLTN_PWR_ID'):
    indices = [index[code] for code in group['TRAN_CD'].unique()]
    for i in indices:
        for j in indices:
            if i != j:
                matrix[i][j] += 1

# Standardize the matrix for clustering
scaler = StandardScaler()
matrix_norm = scaler.fit_transform(matrix)

# Apply K-Means clustering
kmeans = KMeans(n_clusters=3, random_state=0).fit(matrix_norm)
clusters = defaultdict(list)

for code, label in zip(trans_codes, kmeans.labels_):
    clusters[label].append(code)

# Analyze combinations within clusters
results = []
for label, codes in clusters.items():
    for size in range(2, len(codes)+1):
        for combo in combinations(codes, size):
            # Calculate how frequently this combination appears together across all RLTN_PWR_ID
            combo_count = sum(all(c in set(group['TRAN_CD']) for c in combo) for _, group in df.groupby('RLTN_PWR_ID'))
            results.append({'Cluster': label, 'Combination': combo, 'Frequency': combo_count})

# Convert results to a DataFrame
results_df = pd.DataFrame(results)
print(results_df)
