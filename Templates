from pyspark.sql.functions import concat_ws, lit, to_date

# Add the 'execution_date' column and convert it to datetime
prt_agg_df = prt_agg_df.withColumn(
    "execution_date",
    to_date(concat_ws("-", prt_agg_df.execution_year, prt_agg_df.execution_month, lit("01")), "yyyy-MM-dd")
)

# Select and reorder columns
prt_agg_df = prt_agg_df.select(
    "uid_prules", "execution_month", "execution_year", "execution_date", "num_executions"
)

# Rename all columns to uppercase
prt_agg_df = prt_agg_df.toDF(*[col.upper() for col in prt_agg_df.columns])

# Show the updated DataFrame
prt_agg_df.show()
