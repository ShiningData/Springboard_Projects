import pandas as pd
import pyarrow.parquet as pq

# Define the product categories
meat = ['Seafood', 'Beef', 'Pork', 'Exotic Meat', 'Lamb', 'Poultry', 'Protein (Other)']
fruit = ['Fruit & Vegetables']
canned = ['Canned & Dry']
nonAlcic = ['Wine', 'Spirits', 'Beer & Other']  # Non-alcoholic category
bakery = ['Bakery & Bread']
supEq = ['Supplies & Equipment']
diary = ['Dairy & Eggs']
nonAlcBev = ['Beverage']  # Another non-alcoholic category
frozen = ['Frozen']
services = ['Services']

# The complete product list
productList = [meat, fruit, canned, nonAlcic, bakery, supEq, diary, nonAlcBev, frozen, services]
category_names = ['Meat', 'Fruit', 'Canned', 'NonAlcoholic', 'Bakery', 
                  'Supplies', 'Dairy', 'Beverage', 'Frozen', 'Services']

# Function to process parquet data incrementally, filtering for 'NON-ALCHOLIC'
def process_parquet_incrementally(filepath, chunksize=10000):
    """
    Process large Parquet files incrementally and create separate dataframes
    for each product category, filtering for 'NON-ALCHOLIC' values
    
    Args:
        filepath: Path to the Parquet file
        chunksize: Number of rows to process at a time
    
    Returns:
        Dictionary of dataframes for each category
    """
    # Initialize empty dataframes for each category
    category_dfs = {name: pd.DataFrame() for name in category_names}
    
    # Get parquet file metadata
    parquet_file = pq.ParquetFile(filepath)
    total_rows = parquet_file.metadata.num_rows
    
    # Read and process the parquet file in chunks
    total_rows_processed = 0
    total_nonalcoholic_rows = 0
    
    for batch in parquet_file.iter_batches(batch_size=chunksize):
        # Convert Arrow table to pandas DataFrame
        chunk = batch.to_pandas()
        
        # Update progress
        total_rows_processed += len(chunk)
        progress_percent = (total_rows_processed / total_rows) * 100
        print(f"Processing: {total_rows_processed}/{total_rows} rows ({progress_percent:.1f}%)")
        
        # Filter only rows with 'NON-ALCHOLIC' value
        # IMPORTANT: This assumes there's a separate column indicating if a product is non-alcoholic
        # If this is not correct, please adjust the condition
        non_alcoholic_chunk = chunk[chunk['distributor_product_column'] == 'NON-ALCHOLIC']
        total_nonalcoholic_rows += len(non_alcoholic_chunk)
        
        if len(non_alcoholic_chunk) == 0:
            continue  # Skip this chunk if no non-alcoholic products
            
        # Process each category
        for category_name in category_names:
            # Get the corresponding category list from productList
            idx = category_names.index(category_name)
            category_list = productList[idx]
            
            # Filter rows for this category (from the already filtered non-alcoholic chunk)
            category_chunk = non_alcoholic_chunk[non_alcoholic_chunk['distributor_product_column'].isin(category_list)]
            
            # Append to the category dataframe
            if not category_chunk.empty:
                if category_dfs[category_name].empty:
                    category_dfs[category_name] = category_chunk
                else:
                    category_dfs[category_name] = pd.concat([category_dfs[category_name], category_chunk])
    
    # Print summary of results
    print("\nProcessing complete!")
    print(f"Total non-alcoholic rows found: {total_nonalcoholic_rows}")
    for category_name, df in category_dfs.items():
        print(f"{category_name} DataFrame: {len(df)} rows")
    
    return category_dfs

# Function to save each category DataFrame to a separate parquet file
def save_category_dataframes(category_dfs, output_dir='.', format='parquet'):
    """
    Save each category DataFrame to a separate file
    
    Args:
        category_dfs: Dictionary of category dataframes
        output_dir: Directory to save files to
        format: 'parquet' or 'csv'
    """
    import os
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    for category_name, df in category_dfs.items():
        if not df.empty:
            if format.lower() == 'parquet':
                output_path = os.path.join(output_dir, f"{category_name.lower()}_nonalcoholic_products.parquet")
                df.to_parquet(output_path, index=False)
            else:
                output_path = os.path.join(output_dir, f"{category_name.lower()}_nonalcoholic_products.csv")
                df.to_csv(output_path, index=False)
            print(f"Saved {category_name} DataFrame ({len(df)} rows) to {output_path}")

# Usage example:
# Replace with your actual parquet file path
# category_dfs = process_parquet_incrementally('your_data.parquet', chunksize=50000)
# save_category_dataframes(category_dfs, 'output_directory', format='parquet')
